{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the experiment scores\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open(f'outputs/13200_30_scores.pickle', 'rb') as handle:\n",
    "    scores = pickle.load(handle)\n",
    "\n",
    "# scores levels:\n",
    "# 0: {'sas', 'jaccard'}\n",
    "# 1: {'bert', top_tfidf', 'top_bow', 'w2v_weighted', 'w2v_sif'}\n",
    "df_scores=None\n",
    "df_scores = pd.DataFrame(columns=[\n",
    "    'scoreType',\n",
    "    'score'\n",
    "])\n",
    "for score_type in ['sas', 'jaccard']:\n",
    "    for model_type in ['bert', 'top_tfidf', 'top_bow', 'w2v_weighted', 'w2v_sif']:\n",
    "        for i in range(len(scores[score_type][model_type])):\n",
    "            row = {\n",
    "                'scoreType': f'{score_type}({model_type})',\n",
    "                'score': scores[score_type][model_type][i]\n",
    "            }\n",
    "            df_scores = df_scores.append(row, ignore_index=True)\n",
    "    \n",
    "# df_scores.to_csv(f'outputs/1000_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the experiment runtimes\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "df_times = pd.DataFrame(columns=[\n",
    "    'func_name',\n",
    "    'time_elapsed(s)'\n",
    "])\n",
    "    \n",
    "with open('outputs/1000_30_log.txt') as f:\n",
    "    for line in f:\n",
    "        if 'ELAPSED(s)' in line:\n",
    "            line = line.strip()\n",
    "            pieces = line.split('ELAPSED(s)')\n",
    "            curr_func = pieces[0]\n",
    "            time_elapsed = pieces[1]\n",
    "            df_times = df_times.append({\n",
    "                'func_name': curr_func,\n",
    "                'time_elapsed(s)': time_elapsed\n",
    "            }, ignore_index=True)\n",
    "\n",
    "# df_times.to_csv(f'outputs/1000_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_scores_agg = df_scores.groupby(['scoreType']).agg({\n",
    "#     'score': ['mean', 'min', 'max', 'std']\n",
    "# })\n",
    "# df_scores_agg.columns = ['score_mean', 'score_min', 'score_max', 'score_stdev']\n",
    "# df_scores_agg = df_scores_agg.reset_index()\n",
    "df_scores_agg = df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "sas_data = df_scores_agg.loc[df_scores_agg['scoreType'].str.contains('sas(', regex=False)]\n",
    "\n",
    "scale = alt.Scale(\n",
    "#             domain=(-0.06, 0.9),\n",
    "            zero=False\n",
    ")\n",
    "stdev_err = alt.Chart(sas_data).mark_errorbar(extent='stdev').encode(\n",
    "  x=alt.X('scoreType:N'),\n",
    "  y=alt.Y(\n",
    "        'score:Q',\n",
    "        scale=scale\n",
    "    ),\n",
    ")\n",
    "bars = alt.Chart(\n",
    "    sas_data, \n",
    "    title='SAS scores for prob. clust. vs baselines'\n",
    ").mark_bar().encode(\n",
    "    x=alt.X(\n",
    "        'scoreType:N',\n",
    "        axis=alt.Axis(\n",
    "            title='',\n",
    "            labelAngle=-20\n",
    "        )\n",
    "    ),\n",
    "    y=alt.Y(\n",
    "        'score:Q',\n",
    "        aggregate='mean',\n",
    "        scale=scale\n",
    "    ),\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "# (bars + stdev_err).save('sas_chart.png', webdriver='firefox')\n",
    "(bars + stdev_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "jaccard_data = df_scores_agg.loc[df_scores_agg['scoreType'].str.contains('jaccard(', regex=False)]\n",
    "\n",
    "scale = alt.Scale(\n",
    "#             domain=(-0.06, 0.9),\n",
    "            zero=False\n",
    ")\n",
    "stdev_err = alt.Chart(jaccard_data).mark_errorbar(extent='stdev').encode(\n",
    "  x=alt.X('scoreType:N'),\n",
    "  y=alt.Y(\n",
    "        'score:Q',\n",
    "        scale=scale\n",
    "    ),\n",
    ")\n",
    "bars = alt.Chart(\n",
    "    jaccard_data, \n",
    "    title='Jaccard scores for prob. clust. vs baselines'\n",
    ").mark_bar().encode(\n",
    "    x=alt.X(\n",
    "        'scoreType:N',\n",
    "        axis=alt.Axis(\n",
    "            title='',\n",
    "            labelAngle=-20\n",
    "        )\n",
    "    ),\n",
    "    y=alt.Y(\n",
    "        'score:Q',\n",
    "        aggregate='mean',\n",
    "        scale=scale\n",
    "    ),\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "# (bars + stdev_err).save('jaccard_chart.png', webdriver='firefox')\n",
    "(bars + stdev_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
